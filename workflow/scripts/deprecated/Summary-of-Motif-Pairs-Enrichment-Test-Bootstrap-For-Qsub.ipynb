{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f37fbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools as it\n",
    "from collections import defaultdict,Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "from mlbootstrap import bootstrap\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6fd12dd5",
   "metadata": {},
   "source": [
    "## Load Loop-Motif Intersection Data (Script 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6212c515",
   "metadata": {},
   "source": [
    "Script is run once per sample. Output a tsv of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2def1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['loop_anchor1_chr','loop_anchor1_start','loop_anchor1_end','loop_anchor2_chr','loop_anchor2_start','loop_anchor2_end','motif_chr','motif_start','motif_end','motif_id','motif_name']\n",
    "df = pd.read_csv(r\"C:\\Users\\Romeo Ignacio\\Downloads\\loops_overlap_motifs.txt\",sep=\"\\t\",header =None,names=columns)\n",
    "\n",
    "# Get rid of all duplicate motif-pair\n",
    "# (doesn't remove dupliate motifs in a single anchort)\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4c4e153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which anchor a motif falls in\n",
    "df[\"anchor_1\"] = (df['loop_anchor1_start'] <= df['motif_start']) & (df['motif_end'] <= df['loop_anchor1_end']) \n",
    "df[\"anchor_2\"] = (df['loop_anchor2_start'] <= df['motif_start']) & (df['motif_end'] <= df['loop_anchor2_end'])\n",
    "df['anchor_id'] = 1\n",
    "\n",
    "# Drop duplicates if they occur\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Create loop ID\n",
    "df['anchor1_id'] = df['loop_anchor1_chr'] + ':' + df['loop_anchor1_start'].astype(str)\n",
    "df['anchor2_id'] = df['loop_anchor2_chr'] + ':' + df['loop_anchor2_start'].astype(str)\n",
    "df['loop_id'] = df['loop_anchor1_chr'] + ':' + df['loop_anchor1_start'].astype(str) + ':' + df['loop_anchor2_start'].astype(str)\n",
    "\n",
    "# Drop duplicate motif pairs\n",
    "df.drop_duplicates(subset=['loop_id', 'anchor2_id', 'motif_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7f99ddb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f48f57ca",
   "metadata": {},
   "source": [
    "## Count Motif-Pairs in Our Dataset (script 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "38f8338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "motif_pair_counter = Counter()\n",
    "# Count up motif pairs\n",
    "for loop_id, loop_df in df.groupby('loop_id'):\n",
    "    \n",
    "    anchor1_df = loop_df.loc[loop_df.anchor_1 == True]\n",
    "    anchor2_df = loop_df.loc[loop_df.anchor_2 == True]\n",
    "    \n",
    "    if anchor1_df.shape[0] == 0 or anchor2_df.shape[0] == 0:\n",
    "        continue\n",
    "        \n",
    "    motifs1 = list(anchor1_df.motif_name)\n",
    "    motifs2 = list(anchor2_df.motif_name)\n",
    "    perms = list(it.product(motifs1, motifs2))\n",
    "    \n",
    "    for p in perms:\n",
    "        motif_pair_counter[p] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "d0f6ca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ZNF768', 'RREB1')\n",
      "('SP8', 'RREB1')\n",
      "('SP9', 'RREB1')\n",
      "('SP3', 'RREB1')\n",
      "('PATZ1', 'RREB1')\n",
      "('HES1', 'RREB1')\n",
      "('KLF17', 'RREB1')\n",
      "('MAZ', 'RREB1')\n",
      "('ZNF189', 'RREB1')\n",
      "('KLF17', 'EHF')\n",
      "('KLF17', 'FLI1::FOXI1')\n",
      "('KLF17', 'FOXJ2::ELF1')\n",
      "('KLF17', 'FOXO1::ELF1')\n",
      "('KLF17', 'FOXO1::ELK3')\n",
      "('KLF17', 'FOXO1::FLI1')\n",
      "('KLF17', 'ZNF449')\n",
      "('KLF17', 'TFEB')\n",
      "('KLF17', 'KLF4')\n",
      "('KLF17', 'KLF5')\n",
      "('KLF17', 'KLF15')\n",
      "('KLF17', 'ZNF454')\n",
      "('KLF17', 'CTCF')\n",
      "('KLF17', 'CTCFL')\n",
      "('KLF17', 'ZKSCAN5')\n",
      "('KLF17', 'ZNF263')\n",
      "('KLF17', 'ZNF281')\n",
      "('KLF17', 'ZNF148')\n",
      "('KLF17', 'SP5')\n",
      "('KLF17', 'PRDM9')\n",
      "('KLF17', 'NFIB')\n",
      "('KLF17', 'ZNF530')\n",
      "('KLF17', 'ZNF331')\n",
      "('KLF17', 'REST')\n",
      "('KLF17', 'MEF2A')\n",
      "('KLF17', 'MEF2B')\n",
      "('KLF17', 'MEF2D')\n",
      "('KLF17', 'ESR2')\n",
      "('KLF17', 'TFEC')\n",
      "('KLF17', 'ZNF701')\n",
      "('KLF17', 'MAZ')\n",
      "('KLF17', 'ZNF320')\n",
      "('KLF17', 'ZNF93')\n",
      "('ZNF669', 'EHF')\n",
      "('ZNF669', 'FLI1::FOXI1')\n",
      "('ZNF669', 'FOXJ2::ELF1')\n",
      "('ZNF669', 'FOXO1::ELF1')\n",
      "('ZNF669', 'FOXO1::ELK3')\n",
      "('ZNF669', 'FOXO1::FLI1')\n",
      "('ZNF669', 'ZNF449')\n",
      "('ZNF669', 'TFEB')\n",
      "('ZNF669', 'KLF4')\n",
      "('ZNF669', 'KLF5')\n",
      "('ZNF669', 'KLF15')\n",
      "('ZNF669', 'ZNF454')\n",
      "('ZNF669', 'CTCF')\n",
      "('ZNF669', 'CTCFL')\n",
      "('ZNF669', 'ZKSCAN5')\n",
      "('ZNF669', 'ZNF263')\n",
      "('ZNF669', 'ZNF281')\n",
      "('ZNF669', 'ZNF148')\n",
      "('ZNF669', 'SP5')\n",
      "('ZNF669', 'PRDM9')\n",
      "('ZNF669', 'NFIB')\n",
      "('ZNF669', 'ZNF530')\n",
      "('ZNF669', 'ZNF331')\n",
      "('ZNF669', 'REST')\n",
      "('ZNF669', 'MEF2A')\n",
      "('ZNF669', 'MEF2B')\n",
      "('ZNF669', 'MEF2D')\n",
      "('ZNF669', 'RREB1')\n",
      "('ZNF669', 'ESR2')\n",
      "('ZNF669', 'TFEC')\n",
      "('ZNF669', 'ZNF701')\n",
      "('ZNF669', 'MAZ')\n",
      "('ZNF669', 'ZNF320')\n",
      "('ZNF669', 'ZNF93')\n",
      "('AR', 'EHF')\n",
      "('AR', 'FLI1::FOXI1')\n",
      "('AR', 'FOXJ2::ELF1')\n",
      "('AR', 'FOXO1::ELF1')\n",
      "('AR', 'FOXO1::ELK3')\n",
      "('AR', 'FOXO1::FLI1')\n",
      "('AR', 'ZNF449')\n",
      "('AR', 'TFEB')\n",
      "('AR', 'KLF4')\n",
      "('AR', 'KLF5')\n",
      "('AR', 'KLF15')\n",
      "('AR', 'ZNF454')\n",
      "('AR', 'CTCF')\n",
      "('AR', 'CTCFL')\n",
      "('AR', 'ZKSCAN5')\n",
      "('AR', 'ZNF263')\n",
      "('AR', 'ZNF281')\n",
      "('AR', 'ZNF148')\n",
      "('AR', 'SP5')\n",
      "('AR', 'PRDM9')\n",
      "('AR', 'NFIB')\n",
      "('AR', 'ZNF530')\n",
      "('AR', 'ZNF331')\n"
     ]
    }
   ],
   "source": [
    "t = 1\n",
    "dirpath = r\"H:\\Genetics Project\\Statistics\\Pair_Files_Simu\"\n",
    "\n",
    "for motif_pair in motif_pair_counter.items():\n",
    "    # Clean out characters for file neames\n",
    "    folder_name = str(motif_pair[0]).replace(\"'\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"_\").replace(\",\",\"\").replace(\":\",\".\")\n",
    "    # Create File of paired observations\n",
    "    if os.path.exists(dirpath+\"\\\\\"+str(folder_name)):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(dirpath+\"\\\\\"+str(folder_name))\n",
    "    # Save observed file in text file\n",
    "    with open(dirpath+'\\\\'+str(folder_name)+'\\\\'+'simulations.txt', 'w', newline='') as csv_file:\n",
    "        data = [[motif_pair[0],motif_pair[1]]]\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(['Motif_Pair','Observed'])\n",
    "        writer.writerows(data)\n",
    "    t+=1\n",
    "    print(motif_pair[0])\n",
    "    if t == 100:\n",
    "        break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "347bc70d",
   "metadata": {},
   "source": [
    "## Bootstrap Test (Genome-Wide) (Script 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84787bda",
   "metadata": {},
   "source": [
    "Run once per each simulation. Use as input, the results from script 1. Output a column of data where each entry is the number of simulated counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "77bfc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "##Inputs needed, dataframe or text file of dataframe, number of sims you want, and directory path\n",
    "bootstrap_df = df\n",
    "sims = 2\n",
    "dirpath = r\"H:\\Genetics Project\\Statistics\\Pair_Files_Simu\"\n",
    "##Permutate All motifs across the Chromosome\n",
    "sim = 1\n",
    "i = 0\n",
    "results = []\n",
    "all_loop_pairs = []\n",
    "##Create Simulations\n",
    "while sim < 3:\n",
    "    # Get length of bootstrap\n",
    "    n = len(bootstrap_df[\"motif_name\"])\n",
    "\n",
    "    #Randomly sort out permutation column with motifs\n",
    "    bootstrap_df[\"Random_Motif\"] = np.random.choice(df['motif_name'],size=n,replace=True)\n",
    "\n",
    "    #Call in counter function\n",
    "    sim_motif_pair_counter = Counter()\n",
    "    \n",
    "    #Groupby loop id, determine anchors based on positoin\n",
    "    for loop_id, loop_df in df.groupby('loop_id'):\n",
    "        anchor1_df = loop_df.loc[loop_df.anchor_1 == True]\n",
    "        anchor2_df = loop_df.loc[loop_df.anchor_2 == True]\n",
    "\n",
    "        #If missing anchors, skip loop\n",
    "        if anchor1_df.shape[0] == 0 or anchor2_df.shape[0] == 0:\n",
    "            continue\n",
    "\n",
    "        #Get motifs1\n",
    "        motifs1 = list(anchor1_df.Random_Motif)\n",
    "\n",
    "        #Get motifs2\n",
    "        motifs2 = list(anchor2_df.Random_Motif)\n",
    "\n",
    "        # get motif-pair combinations\n",
    "        combs = list(it.product(motifs1, motifs2))\n",
    "\n",
    "        # count each combination\n",
    "        for c in combs:\n",
    "            sim_motif_pair_counter[c] += 1\n",
    "    results.append(sim_motif_pair_counter)\n",
    "    print(sim)\n",
    "    sim += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "24fb3584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "t = 1\n",
    "for motif_pair in motif_pair_counter.items():\n",
    "    sim = 0\n",
    "    while sim < sims:\n",
    "        # Clean out characters for file neames\n",
    "        folder_name = str(motif_pair[0]).replace(\"'\",\"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"_\").replace(\",\",\"\").replace(\":\",\".\")\n",
    "        with open(dirpath+'\\\\'+str(folder_name)+'\\\\'+'simulations.txt', 'r') as infile:\n",
    "            reader = csv.reader(infile)\n",
    "            data = list(reader)\n",
    "            \n",
    "\n",
    "        # Add the new header to the first row of the list of lists\n",
    "        data[0].append(\"sim\"+str(sim))\n",
    "\n",
    "        # Add the new data to the remaining rows of the list of lists\n",
    "        data[1].append(results[sim][motif_pair[0]])\n",
    "        dataentry = [data[1]]\n",
    "        # Append the updated list of lists to an existing CSV file\n",
    "        with open(dirpath+'\\\\'+str(folder_name)+'\\\\'+'simulations.txt', 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(data[0])\n",
    "            writer.writerows(dataentry)\n",
    "        sim+=1\n",
    "    t+=1\n",
    "    print(t)\n",
    "    if t == 100:\n",
    "        break\n",
    "            "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85316699",
   "metadata": {},
   "source": [
    "## Aggregate the simulation data (Script 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "b1cb8784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR_CTCF\n",
      "AR_CTCFL\n",
      "AR_EHF\n",
      "AR_FLI1..FOXI1\n",
      "AR_FOXJ2..ELF1\n",
      "AR_FOXO1..ELF1\n",
      "AR_FOXO1..ELK3\n",
      "AR_FOXO1..FLI1\n",
      "AR_KLF15\n",
      "AR_KLF4\n",
      "AR_KLF5\n",
      "AR_NFIB\n",
      "AR_PRDM9\n",
      "AR_SP5\n",
      "AR_TFEB\n",
      "AR_ZKSCAN5\n",
      "AR_ZNF148\n",
      "AR_ZNF263\n",
      "AR_ZNF281\n",
      "AR_ZNF331\n",
      "AR_ZNF449\n",
      "AR_ZNF454\n",
      "AR_ZNF530\n",
      "HES1_RREB1\n",
      "KLF17_CTCF\n",
      "KLF17_CTCFL\n",
      "KLF17_EHF\n",
      "KLF17_ESR2\n",
      "KLF17_FLI1..FOXI1\n",
      "KLF17_FOXJ2..ELF1\n",
      "KLF17_FOXO1..ELF1\n",
      "KLF17_FOXO1..ELK3\n",
      "KLF17_FOXO1..FLI1\n",
      "KLF17_KLF15\n",
      "KLF17_KLF4\n",
      "KLF17_KLF5\n",
      "KLF17_MAZ\n",
      "KLF17_MEF2A\n",
      "KLF17_MEF2B\n",
      "KLF17_MEF2D\n",
      "KLF17_NFIB\n",
      "KLF17_PRDM9\n",
      "KLF17_REST\n",
      "KLF17_RREB1\n",
      "KLF17_SP5\n",
      "KLF17_TFEB\n",
      "KLF17_TFEC\n",
      "KLF17_ZKSCAN5\n",
      "KLF17_ZNF148\n",
      "KLF17_ZNF263\n",
      "KLF17_ZNF281\n",
      "KLF17_ZNF320\n",
      "KLF17_ZNF331\n",
      "KLF17_ZNF449\n",
      "KLF17_ZNF454\n",
      "KLF17_ZNF530\n",
      "KLF17_ZNF701\n",
      "KLF17_ZNF93\n",
      "MAZ_RREB1\n",
      "PATZ1_RREB1\n",
      "SP3_RREB1\n",
      "SP8_RREB1\n",
      "SP9_RREB1\n",
      "ZNF189_RREB1\n",
      "ZNF669_CTCF\n",
      "ZNF669_CTCFL\n",
      "ZNF669_EHF\n",
      "ZNF669_ESR2\n",
      "ZNF669_FLI1..FOXI1\n",
      "ZNF669_FOXJ2..ELF1\n",
      "ZNF669_FOXO1..ELF1\n",
      "ZNF669_FOXO1..ELK3\n",
      "ZNF669_FOXO1..FLI1\n",
      "ZNF669_KLF15\n",
      "ZNF669_KLF4\n",
      "ZNF669_KLF5\n",
      "ZNF669_MAZ\n",
      "ZNF669_MEF2A\n",
      "ZNF669_MEF2B\n",
      "ZNF669_MEF2D\n",
      "ZNF669_NFIB\n",
      "ZNF669_PRDM9\n",
      "ZNF669_REST\n",
      "ZNF669_RREB1\n",
      "ZNF669_SP5\n",
      "ZNF669_TFEB\n",
      "ZNF669_TFEC\n",
      "ZNF669_ZKSCAN5\n",
      "ZNF669_ZNF148\n",
      "ZNF669_ZNF263\n",
      "ZNF669_ZNF281\n",
      "ZNF669_ZNF320\n",
      "ZNF669_ZNF331\n",
      "ZNF669_ZNF449\n",
      "ZNF669_ZNF454\n",
      "ZNF669_ZNF530\n",
      "ZNF669_ZNF701\n",
      "ZNF669_ZNF93\n",
      "ZNF768_RREB1\n"
     ]
    }
   ],
   "source": [
    "## Loop through all files\n",
    "\n",
    "sig_level = 0.95\n",
    "dirpath = r\"H:\\Genetics Project\\Statistics\\Pair_Files_Simu/\"\n",
    "savepath = r\"H:\\Genetics Project\\Statistics\\Results\"\n",
    "\n",
    "# Determine if file exists.  If does, delete\n",
    "outputpath = savepath+\"\\\\\"+\"p_values.txt\"\n",
    "if os.path.exists(outputpath):\n",
    "        os.remove(outputpath)\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# Put in names of columns of dataframe\n",
    "with open(outputpath, 'w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Motif_Pair','Observed','P-value','Significant'])\n",
    "for folder_name in os.listdir(dirpath):\n",
    "    print(folder_name)\n",
    "    \n",
    "    with open(dirpath+'\\\\'+str(folder_name)+'\\\\'+'simulations.txt', 'r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        data = list(reader)\n",
    "\n",
    "    \n",
    "\n",
    "    with open(outputpath, 'a', newline='') as csv_file:\n",
    "        listnum = [int(num) for num in data[1][1:]]\n",
    "        sims = len(listnum[1:])\n",
    "        p_value = len([num for num in listnum[1:] if num <= listnum[0]])/sims\n",
    "        sig = p_value >= sig_level\n",
    "\n",
    "        # If significant, output message, \"Yes\".  \"No\" otherwise\n",
    "        if sig == 1:\n",
    "            message = \"Yes\"\n",
    "        else:\n",
    "            message = \"No\"\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerows([[data[1][0],data[1][1],p_value,message]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "568f0237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listnum[1:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
